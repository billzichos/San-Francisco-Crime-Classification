# merge the snapshot and results files, creating a single dataset
comb <- merge(snapshot, results, by.x = 'Deal.Number', by.y = 'Deal.Number')
# summary(comb)
# str(comb)
# update the closedsaswon field based on the value in the status field.
comb$ClosedAsWon[comb$Status=="Lost"] <- 0
comb$ClosedAsWon[comb$Status=="Won"] <- 1
# add only the fields from the snapshot dataset to the final dataset.
completeDataset <- select(comb, 1:21)
# str(completeDataset)
# str(completeDataset$ClosedAsWon)
# summary(completeDataset)
# summary(completeDataset$ClosedAsWon)
# overwrite the orginal snapshot file
write.csv(completeDataset,paste("~//Private-Github-Files//",snapshotFilename, sep = ""), row.names = FALSE)
#Update the periodic snapshot with Results if known
library(dplyr)
# setwd("~/Private-Github-Files")
# specify the snapshot file to update with actual results
snapshotFilename <- "OpenDeals20150804.csv"
# import the actual results
results <- read.csv("~//Private-Github-Files//results.csv")
# str(results)
# import the point-in-time snapshot
snapshot <- read.csv(paste("~//Private-Github-Files//", snapshotFilename, sep =""))
# str(snapshot)
# summary(snapshot)
# merge the snapshot and results files, creating a single dataset
comb <- merge(snapshot, results, by.x = 'Deal.Number', by.y = 'Deal.Number')
# summary(comb)
# str(comb)
# update the closedsaswon field based on the value in the status field.
comb$ClosedAsWon[comb$Status=="Lost"] <- 0
comb$ClosedAsWon[comb$Status=="Won"] <- 1
# add only the fields from the snapshot dataset to the final dataset.
completeDataset <- select(comb, 1:21)
# str(completeDataset)
# str(completeDataset$ClosedAsWon)
# summary(completeDataset)
# summary(completeDataset$ClosedAsWon)
# overwrite the orginal snapshot file
write.csv(completeDataset,paste("~//Private-Github-Files//",snapshotFilename, sep = ""), row.names = FALSE)
wd <- "~/GitHub/Titanic-Machine-Learning-From-Disaster"
setwd(wd)
# read in the training file and prepare for combining with test.
train <- read.csv("train.csv")
train$Source <- "Train"
# read in the test file and prepare for combining with train.
test <- read.csv("test.csv")
test$Source <- "Test"
# add the Survived column to the test dataset
test$Survived <- rep(0, nrow(test))
# combine the two datasets into single data frame
df <- rbind(train, test)
# format as factors
df$Pclass <- factor(df$Pclass, ordered=FALSE)
df$Sex <- as.factor(df$Sex, ordered = FALSE)
# impute Fare using the median fare price.
df$Fare[is.na(df$Fare)] <- median(df$Fare, na.rm=TRUE)
# impute Embarked by marking all NULLS as originating in Southampton
df$Embarked[which(df$Embarked=="")] <- "S"
df$Embarked <- as.factor(df$Embarked)
# Name
library(reshape)
nameSplit <- colsplit(df$Name, "[,.] | [ ]", c("lastName", "title", "otherName1", "otherName2"))
df <- cbind(df, nameSplit)
df$lastName <- as.character(df$lastName)
df$otherName1 <- as.character(df$otherName1)
df$otherName2 <- as.character(df$otherName2)
df$titleRollup1 <-
as.factor(ifelse(df$title=="Mr", "MR",
ifelse(df$title=="Master", "MR",
ifelse(df$title=="Don", "MR",
ifelse(df$title=="Dona", "MISS",
ifelse(df$title=="Miss", "MISS",
ifelse(df$title=="Ms", "MISS",
ifelse(df$title=="Mlle", "MISS",
ifelse(df$title=="Mrs", "MRS",
ifelse(df$title=="Mme", "MRS",
ifelse(df$title=="Rev", "REV",
ifelse(df$title=="Dr", "DR",
ifelse(df$title=="the Countess", "COUNTESS",
ifelse(df$title=="Major", "MAJ",
ifelse(df$title=="Lady", "LADY",
ifelse(df$title=="Sir", "SIR",
ifelse(df$title=="Col", "COL",
ifelse(df$title=="Capt", "CAPT",
ifelse(df$title=="Jonkheer", "JONKHEER", "Unknown")))))))))))))))))))
df$titleRollup2 <-
as.factor(ifelse(df$title=="Mr", "OTHER",
ifelse(df$title=="Master", "OTHER",
ifelse(df$title=="Don", "ROYALTY",
ifelse(df$title=="Dona", "ROYALTY",
ifelse(df$title=="Miss", "OTHER",
ifelse(df$title=="Ms", "OTHER",
ifelse(df$title=="Mlle", "OTHER",
ifelse(df$title=="Mrs", "OTHER",
ifelse(df$title=="Mme", "OTHER",
ifelse(df$title=="Rev", "CLERGY",
ifelse(df$title=="Dr", "DOCTOR",
ifelse(df$title=="the Countess", "ROYALTY",
ifelse(df$title=="Major", "MILITARY",
ifelse(df$title=="Lady", "ROYALTY",
ifelse(df$title=="Sir", "ROYALTY",
ifelse(df$title=="Col", "MILITARY",
ifelse(df$title=="Capt", "MILITARY",
ifelse(df$title=="Jonkheer", "ROYALTY", "Unknown")))))))))))))))))))
strsplit(df$Cabin, '[A-Z]')
help(strsplit)
strsplit(df$Cabin)
strsplit(df$Cabin,"")
strsplit(df$Cabin," ")
strsplit(df$Cabin,"a")
strsplit(df$Cabin,"#")
df$Cabin <- as.character(df$Cabin)
strsplit(df$Cabin,"#")
strsplit(df$Cabin,"[A-Z]")
strsplit(df$Cabin,"[A-Z]")[[1]][[2]]
strsplit(df$Cabin,"[A-Z]")[[1]]
strsplit(df$Cabin,"[A-Z]")[1]
strsplit(df$Cabin,"[A-Z]")
df$CabinNum <- sapply(df$Cabin, function(x) strsplit(x, '[A-Z]')[[1]][[2]])
df$CabinNum <- sapply(df$Cabin, function(x) strsplit(x, '[A-Z]')[[1]][2])
df$CabinNum <- as.numeric(df$CabinNum)
wd <- "~/GitHub/Titanic-Machine-Learning-From-Disaster"
setwd(wd)
# read in the training file and prepare for combining with test.
train <- read.csv("train.csv")
train$Source <- "Train"
# read in the test file and prepare for combining with train.
test <- read.csv("test.csv")
test$Source <- "Test"
# add the Survived column to the test dataset
test$Survived <- rep(0, nrow(test))
# combine the two datasets into single data frame
df <- rbind(train, test)
# format as factors
df$Pclass <- factor(df$Pclass, ordered=FALSE)
df$Sex <- as.factor(df$Sex, ordered = FALSE)
# impute Fare using the median fare price.
df$Fare[is.na(df$Fare)] <- median(df$Fare, na.rm=TRUE)
# impute Embarked by marking all NULLS as originating in Southampton
df$Embarked[which(df$Embarked=="")] <- "S"
df$Embarked <- as.factor(df$Embarked)
# impute Age with -1
df$Age[is.na(df$Age)] <- -1
# extract cabin number from cabin
df$Cabin <- as.character(df$Cabin)
df$CabinNum <- sapply(df$Cabin, function(x) strsplit(x, '[A-Z]')[[1]][2])
df$CabinNum <- as.numeric(df$CabinNum)
# classify the cabins into 1 of 3 areas based on cabin number
df$CabinPos[df$CabinNum<50] <- "Forward"
df$CabinPos[df$CabinNum>=50 & df$CabinNum<100] <- "Middle"
df$CabinPos[df$CabinNum>=1000] <- "Aft"
df$CabinPos <- as.factor(df$CabinPos)
# Name
library(reshape)
nameSplit <- colsplit(df$Name, "[,.] | [ ]", c("lastName", "title", "otherName1", "otherName2"))
df <- cbind(df, nameSplit)
df$lastName <- as.character(df$lastName)
df$otherName1 <- as.character(df$otherName1)
df$otherName2 <- as.character(df$otherName2)
df$titleRollup1 <-
as.factor(ifelse(df$title=="Mr", "MR",
ifelse(df$title=="Master", "MR",
ifelse(df$title=="Don", "MR",
ifelse(df$title=="Dona", "MISS",
ifelse(df$title=="Miss", "MISS",
ifelse(df$title=="Ms", "MISS",
ifelse(df$title=="Mlle", "MISS",
ifelse(df$title=="Mrs", "MRS",
ifelse(df$title=="Mme", "MRS",
ifelse(df$title=="Rev", "REV",
ifelse(df$title=="Dr", "DR",
ifelse(df$title=="the Countess", "COUNTESS",
ifelse(df$title=="Major", "MAJ",
ifelse(df$title=="Lady", "LADY",
ifelse(df$title=="Sir", "SIR",
ifelse(df$title=="Col", "COL",
ifelse(df$title=="Capt", "CAPT",
ifelse(df$title=="Jonkheer", "JONKHEER", "Unknown")))))))))))))))))))
df$titleRollup2 <-
as.factor(ifelse(df$title=="Mr", "OTHER",
ifelse(df$title=="Master", "OTHER",
ifelse(df$title=="Don", "ROYALTY",
ifelse(df$title=="Dona", "ROYALTY",
ifelse(df$title=="Miss", "OTHER",
ifelse(df$title=="Ms", "OTHER",
ifelse(df$title=="Mlle", "OTHER",
ifelse(df$title=="Mrs", "OTHER",
ifelse(df$title=="Mme", "OTHER",
ifelse(df$title=="Rev", "CLERGY",
ifelse(df$title=="Dr", "DOCTOR",
ifelse(df$title=="the Countess", "ROYALTY",
ifelse(df$title=="Major", "MILITARY",
ifelse(df$title=="Lady", "ROYALTY",
ifelse(df$title=="Sir", "ROYALTY",
ifelse(df$title=="Col", "MILITARY",
ifelse(df$title=="Capt", "MILITARY",
ifelse(df$title=="Jonkheer", "ROYALTY", "Unknown")))))))))))))))))))
library("rpart")
predicted.age <- rpart(Age ~ Pclass + Sex + SibSp + Parch + Fare + Embarked + title + FamilySize, data = df[!is.na(df$Age),], method = "anova")
wd <- "~/GitHub/Titanic-Machine-Learning-From-Disaster"
setwd(wd)
# read in the training file and prepare for combining with test.
train <- read.csv("train.csv")
train$Source <- "Train"
# read in the test file and prepare for combining with train.
test <- read.csv("test.csv")
test$Source <- "Test"
# add the Survived column to the test dataset
test$Survived <- rep(0, nrow(test))
# combine the two datasets into single data frame
df <- rbind(train, test)
# format as factors
df$Pclass <- factor(df$Pclass, ordered=FALSE)
df$Sex <- as.factor(df$Sex, ordered = FALSE)
# impute Fare using the median fare price.
df$Fare[is.na(df$Fare)] <- median(df$Fare, na.rm=TRUE)
# impute Embarked by marking all NULLS as originating in Southampton
df$Embarked[which(df$Embarked=="")] <- "S"
df$Embarked <- as.factor(df$Embarked)
# extract cabin number from cabin
df$Cabin <- as.character(df$Cabin)
df$CabinNum <- sapply(df$Cabin, function(x) strsplit(x, '[A-Z]')[[1]][2])
df$CabinNum <- as.numeric(df$CabinNum)
# classify the cabins into 1 of 3 areas based on cabin number
df$CabinPos[df$CabinNum<50] <- "Forward"
df$CabinPos[df$CabinNum>=50 & df$CabinNum<100] <- "Middle"
df$CabinPos[df$CabinNum>=1000] <- "Aft"
df$CabinPos <- as.factor(df$CabinPos)
# derive a family size feature
df$FamilySize <- df$SibSp + df$Parch + 1
# Name
library(reshape)
nameSplit <- colsplit(df$Name, "[,.] | [ ]", c("lastName", "title", "otherName1", "otherName2"))
df <- cbind(df, nameSplit)
df$lastName <- as.character(df$lastName)
df$otherName1 <- as.character(df$otherName1)
df$otherName2 <- as.character(df$otherName2)
df$titleRollup1 <-
as.factor(ifelse(df$title=="Mr", "MR",
ifelse(df$title=="Master", "MR",
ifelse(df$title=="Don", "MR",
ifelse(df$title=="Dona", "MISS",
ifelse(df$title=="Miss", "MISS",
ifelse(df$title=="Ms", "MISS",
ifelse(df$title=="Mlle", "MISS",
ifelse(df$title=="Mrs", "MRS",
ifelse(df$title=="Mme", "MRS",
ifelse(df$title=="Rev", "REV",
ifelse(df$title=="Dr", "DR",
ifelse(df$title=="the Countess", "COUNTESS",
ifelse(df$title=="Major", "MAJ",
ifelse(df$title=="Lady", "LADY",
ifelse(df$title=="Sir", "SIR",
ifelse(df$title=="Col", "COL",
ifelse(df$title=="Capt", "CAPT",
ifelse(df$title=="Jonkheer", "JONKHEER", "Unknown")))))))))))))))))))
df$titleRollup2 <-
as.factor(ifelse(df$title=="Mr", "OTHER",
ifelse(df$title=="Master", "OTHER",
ifelse(df$title=="Don", "ROYALTY",
ifelse(df$title=="Dona", "ROYALTY",
ifelse(df$title=="Miss", "OTHER",
ifelse(df$title=="Ms", "OTHER",
ifelse(df$title=="Mlle", "OTHER",
ifelse(df$title=="Mrs", "OTHER",
ifelse(df$title=="Mme", "OTHER",
ifelse(df$title=="Rev", "CLERGY",
ifelse(df$title=="Dr", "DOCTOR",
ifelse(df$title=="the Countess", "ROYALTY",
ifelse(df$title=="Major", "MILITARY",
ifelse(df$title=="Lady", "ROYALTY",
ifelse(df$title=="Sir", "ROYALTY",
ifelse(df$title=="Col", "MILITARY",
ifelse(df$title=="Capt", "MILITARY",
ifelse(df$title=="Jonkheer", "ROYALTY", "Unknown")))))))))))))))))))
#impute Age
# impute Age with -1
#df$Age[is.na(df$Age)] <- -1
#impute Age based on decision tree
library("rpart")
predicted.age <- rpart(Age ~ Pclass + Sex + SibSp + Parch + Fare + Embarked + title + FamilySize, data = df[!is.na(df$Age),], method = "anova")
df$Age[is.na(df$Age)] <- predict(predicted.age, df[is.na(df$Age),1])
df[is.na(df$Age),1]
df$Age[is.na(df$Age)] <- predict(predicted.age, df[is.na(df$Age),])
summary(df)
setwd("~/GitHub/San-Francisco-Crime-Classification")
# read in the training file and prepare for combining with test.
train <- read.csv("train.csv")
train$Source <- "Train"
train$Id <- 0
# read in the test file and prepare for combining with train.
test <- read.csv("test.csv")
test$Source <- "Test"
test$Category <- ""
test$Descript <- ""
test$Resolution <- ""
# combine the data files for feature generation
library("dplyr")
train <- select(train, Id, Dates, Category, Descript, DayOfWeek, PdDistrict, Resolution, Address, X, Y, Source)
test <- select(test, Id, Dates, Category, Descript, DayOfWeek, PdDistrict, Resolution, Address, X, Y, Source)
df <- rbind(train, test)
# add variables that are needed for submission
sub <- read.csv("sampleSubmission.csv")
cols <- names(sub)[2:length(names(sub))]
cols <- gsub("\\.", " ", cols)
cols[8] <- "DRUG/NARCOTIC"
cols[13] <- "FORGERY/COUNTERFEITING"
cols[17] <- "LARCENY/THEFT"
cols[21] <- "NON-CRIMINAL"
cols[23] <- "PORNOGRAPHY/OBSCENE MAT"
df[,c(cols)] <- 0
for (i in cols) {df[df$Category==i,i] <- 1}
# derive some date/time-related variables
library("lubridate")
df$Dates.Hour <- hour(df$Dates)
df$Dates.Quarter <- quarter(df$Dates)
df$Dates.Month <- month(df$Dates)
df$Dates.Wkdy <- wday(df$Dates)
df$Dates.LogNumeric <- log10(as.numeric(as.POSIXct(df$Dates)))
# derive some PD District-related variables
pdCols <- unique(df$PdDistrict)
pdCols <- paste("PdDistrict.", pdCols, ".flag", sep = "")
df[,c(pdCols)] <- 0
for (i in pdCols) {df[df$PdDistrict==gsub(".flag|PdDistrict.", "", i),i] <- 1}
# derive some address-related features
# if intersection:
df$Address.Intersection.Street1 <- ""
df$Address.Intersection.Street2 <- ""
# split the string on " " - strsplit("1500 Block of OAK ST", " ")
# remove "/", "ST", "AV" anything else?
# confirm only 2 values remain
# order the values alphabetically
# capture first alpha ordered street in df$Address.Intersection.Street1
# capture 2nd alpha ordered street in df$Address.Intersection.Street2
# if block:
df$Address.Block.Number <- 0
df$Address.Block.Street < ""
# capture block number in df$Address.Block.Number
# capture street name in df$Address.Block.Street
# intersections - OAK ST / LAGUNA ST
grep(" / ", df$Address)
# blocks - 1500 Block of ####
grep("Block of", df$Address)
grep("^[0:9]{1,6} Block of ", df$Address)
strsplit(df$Address, " ")
# Does AVE vs. ST mean anything like it does in NY - NS vs. EW?
# The numbered avenues run N/S and make up the Sunset District on the West Side.
# Does the ordering of streets for intersections have any meaning?
sanFranAddress <- function(x) {
# if intersection:
if() {
}
# remove "/", "ST", "AV" anything else?
# confirm only 2 values remain
# order the values alphabetically
# capture first alpha ordered street in df$Address.Intersection.Street1
# capture 2nd alpha ordered street in df$Address.Intersection.Street2
# intersections - OAK ST / LAGUNA ST
# if block:
else if(grepl("^[0:9]{1,6} Block of ", df$Address)) {
}
# split the string on " " - strsplit("1500 Block of OAK ST", " ")
# capture block number in df$Address.Block.Number
# capture street name in df$Address.Block.Street
}
# block
# street number
# street name 1
# street name 2
# street type
# derive some lat/long-related features
# hemisphere
df$X.WesternHemisphere.Flag <- 0
df$Y.NorthernHemisphere.Flag <- 0
# degrees
df$X.degrees <- as.character(abs(df$X))
df$Y.degrees <- 0
# minutes
# seconds
# fraction
train.temporal.features$Dates <- NULL
train.temporal.features$Descript <- NULL
train.temporal.features$DayOfWeek <- NULL
train.temporal.features$PdDistrict <- NULL
train.temporal.features$Resolution <- NULL
train.temporal.features$Address <- NULL
train.temporal.features$X <- NULL
train.temporal.features$Y <- NULL
km <- kmeans(train.temporal.features, 36, iter.max = 10)
table(train$Category, km$cluster)
train$temporal.kmean.cluster <- km$cluster
#head(train)
#str(train)
str(train.temporal.features)
#summary(train)
#table(train$Category)
#plot(train$Category)
#What is the most common crime in San Francisco?
which.max(summary(train$Category))
plot(train$Category)
#What is the middle Latitude? Longitude?
#Use the mean lat/longs to divide the city into quadrants.
#What is the most common crime by quadrant?
mean(train$X)
mean(train$Y)
plot(train$Y)
with(train, plot(X,Y))
trainClean <- train[which(train$Y!=90),]
with(trainClean, plot(X,Y))
vLine <- mean(trainClean$X)
hLine <- mean(trainClean$Y)
library("ggplot2")
g <- ggplot(trainClean, aes(X,Y))
g + geom_point(aes(color=Category)) +
geom_hline(aes(yintercept = hLine)) +
geom_vline(aes(xintercept = vLine))
trainClean$Quadrant <- 1
trainClean$Quadrant[trainClean$Y>=hLine & trainClean$X>vLine] <- 2
trainClean$Quadrant[trainClean$Y<hLine & trainClean$X>vLine] <- 3
trainClean$Quadrant[trainClean$Y<hLine & trainClean$X<=vLine] <- 4
summary(trainClean$Quadrant)
#What is the most common crime for each Quadrant?
which.max(summary(trainClean$Category[trainClean$Quadrant==1]))
which.max(summary(trainClean$Category[trainClean$Quadrant==2]))
which.max(summary(trainClean$Category[trainClean$Quadrant==3]))
which.max(summary(trainClean$Category[trainClean$Quadrant==4]))
# To prove the point that some crimes are very isolated.
g <- ggplot(trainClean[which(trainClean$Category=="PROSTITUTION"),], aes(X,Y))
g + geom_point(aes(color=Category)) +
geom_hline(aes(yintercept = hLine)) +
geom_vline(aes(xintercept = vLine))
g <- ggplot(trainClean[which(trainClean$Category=="LOITERING"),], aes(X,Y))
g + geom_point(aes(color=Category)) +
geom_hline(aes(yintercept = hLine)) +
geom_vline(aes(xintercept = vLine))
#Let's look for other crimes that are heavily dependant on location.
g <- ggplot(trainClean, aes(X,Y))
g + geom_point(alpha = 1/20) + facet_wrap( ~ Category, nrow = 8, ncol = 5)
#What was the deal with those crimes on the 90th degree of latitude?
length(train[train$Y==90,2])
summary(train[train$Y==90,2])
which.max(summary(train[train$Y==90,2]))
#Dig into the hour of the day.
hours <- 0:23
findMax <- function(x) {
which.max(summary(trainClean$Category[trainClean$Hour==x]))
}
sapply(hours, findMax)
g <- ggplot(trainClean[trainClean$Hour==12 & trainClean$Category!='LARCENY/THEFT',], aes(X,Y))
g + geom_point(alpha = 1/5) + facet_wrap( ~ Category, nrow = 8, ncol = 5)
# Let's look at how critical hour of day
g <- ggplot(trainClean[trainClean$Category=='ARSON',], aes(Hour))
g + geom_bar() + facet_grid(Category ~ .)
plot(trainClean[,c(10:14)], col = cl$cluster)
# add some date/time-related features
library("lubridate")
train.temporal.features <- train
train.temporal.features$Hour <- hour(train$Dates)
train.temporal.features$Quarter <- quarter(train$Dates)
train.temporal.features$Month <- month(train$Dates)
train.temporal.features$Wkdy <- wday(train$Dates)
train.temporal.features$Numeric <- log10(as.numeric(as.POSIXct(train$Dates)))
train.temporal.features$Category <- NULL
train.temporal.features$Dates <- NULL
train.temporal.features$Descript <- NULL
train.temporal.features$DayOfWeek <- NULL
train.temporal.features$PdDistrict <- NULL
train.temporal.features$Resolution <- NULL
train.temporal.features$Address <- NULL
train.temporal.features$X <- NULL
train.temporal.features$Y <- NULL
setwd("~/GitHub/San-Francisco-Crime-Classification")
# read in the training file and prepare for combining with test.
train <- read.csv("train.csv")
train$Source <- "Train"
train$Id <- 0
# read in the test file and prepare for combining with train.
test <- read.csv("test.csv")
test$Source <- "Test"
test$Category <- ""
test$Descript <- ""
test$Resolution <- ""
wd <- "~/GitHub/San-Francisco-Crime-Classification"
setwd(wd)
# The following files are provided
#   - test.csv.zip
#   - train.csv.zip
#   - sampleSubmission.csv.zip
source("~/GitHub/Get-Raw-Data/download.R")
downloadSingleKaggleZip("sf-crime","test.csv.zip", "test.csv")
downloadSingleKaggleZip("sf-crime","train.csv.zip", "train.csv")
downloadSingleKaggleZip("sf-crime","sampleSubmission.csv.zip", "sampleSubmission.csv")
source("~/GitHub/Get-Raw-Data/download.R")
downloadSingleKaggleZip("sf-crime","train.csv.zip", "train.csv")
white.crime <- c("FRAUD", "FORGERY/COUNTERFEITING", "BAD CHECKS", "EXTORTION",
"EMBEZZLEMENT", "SUSPICIOUS OCC", "BRIBERY")
blue.crime <- c("VANDALISM", "LARCENY/THEFT", "STOLEN PROPERTY", "ROBBERY",
"DRIVING UNDER THE INFLUENCE", "DISORDERLY CONDUCT",
"LIQUOR LAWS", "VEHICLE THEFT", "ASSAULT", "KIDNAPPING",
"TRESPASS", "ARSON", "RECOVERED VEHICLE")
white.crime <- c("FRAUD", "FORGERY/COUNTERFEITING", "BAD CHECKS", "EXTORTION",
"EMBEZZLEMENT", "SUSPICIOUS OCC", "BRIBERY")
blue.crime <- c("VANDALISM", "LARCENY/THEFT", "STOLEN PROPERTY", "ROBBERY",
"DRIVING UNDER THE INFLUENCE", "DISORDERLY CONDUCT",
"LIQUOR LAWS", "VEHICLE THEFT", "ASSAULT", "KIDNAPPING",
"TRESPASS", "ARSON", "RECOVERED VEHICLE")
other.crime <- c("MISSING PERSON", "RUNAWAY", "FAMILY OFFENSES", "SEX OFFENSES NON FORCIBLE",
"PORNOGRAPHY/OBSCENSE MAT", "WEAPON LAWS", "DRUNKENNESS", "SUICIDE",
"TREA", "DRUG/NARCOTIC", "SEX OFFENSES FORCIBLE", "LOITERING")
